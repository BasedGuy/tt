<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Talk Track - Sales Meeting Recorder</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; color: white; }
        .container { max-width: 500px; margin: 0 auto; background: rgba(255,255,255,0.1); backdrop-filter: blur(10px); border-radius: 20px; padding: 25px; }
        h1 { text-align: center; margin-bottom: 20px; }
        .status-box { background: rgba(0,0,0,0.2); border-radius: 15px; padding: 20px; margin: 20px 0; text-align: center; }
        #status { font-size: 18px; font-weight: 500; }
        .timer { font-size: 48px; font-weight: 700; margin: 15px 0; }
        .controls { display: grid; grid-template-columns: repeat(3, 1fr); gap: 12px; margin: 25px 0; }
        .btn { padding: 16px; border: none; border-radius: 12px; font-size: 16px; font-weight: 600; cursor: pointer; color: white; display: flex; flex-direction: column; align-items: center; gap: 8px; }
        .btn:active { transform: scale(0.95); }
        .btn:disabled { opacity: 0.5; cursor: not-allowed; transform: none; }
        .record-btn { background: linear-gradient(45deg, #ef4444, #dc2626); }
        .pause-btn { background: linear-gradient(45deg, #f59e0b, #d97706); }
        .stop-btn { background: linear-gradient(45deg, #10b981, #059669); }
        .transcribe-btn { background: linear-gradient(45deg, #3b82f6, #1d4ed8); }
        .audio-container { margin-top: 30px; display: none; }
        audio { width: 100%; border-radius: 10px; margin: 10px 0; }
        .upload-status { background: rgba(0,0,0,0.2); border-radius: 10px; padding: 15px; margin-top: 20px; text-align: center; display: none; }
        .transcript-container { margin-top: 20px; display: none; }
        .transcript-box { background: rgba(0,0,0,0.2); border-radius: 10px; padding: 15px; max-height: 300px; overflow-y: auto; text-align: left; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Talk Track</h1>
        
        <div class="status-box">
            <div id="status">Ready to record</div>
            <div class="timer" id="timer">00:00</div>
        </div>
        
        <div class="controls">
            <button class="btn record-btn" id="recordBtn">‚óè Record</button>
            <button class="btn pause-btn" id="pauseBtn" disabled>‚è∏Ô∏è Pause</button>
            <button class="btn stop-btn" id="stopBtn" disabled>‚èπÔ∏è Stop</button>
        </div>
        
        <div class="audio-container" id="audioContainer">
            <p>Your recording:</p>
            <audio id="audioPlayback" controls></audio>
            <button class="btn transcribe-btn" id="transcribeBtn" style="width:100%;margin-top:15px;">ü§ñ Transcribe with AI</button>
        </div>
        
        <div class="transcript-container" id="transcriptContainer">
            <h3>Transcript</h3>
            <div class="transcript-box" id="transcriptBox"></div>
            <button class="btn" id="saveTranscriptBtn" style="background:linear-gradient(45deg,#10b981,#059669);width:100%;margin-top:15px;">
                üíæ Save Transcript
            </button>
        </div>
        
        <div class="upload-status" id="uploadStatus">
            <div id="uploadMessage">Processing...</div>
        </div>
    </div>

    <script>
        // ========== CONFIGURATION ==========
        const API_KEY = '6fc9030ecb074dc88055f8a257aff0f7';
        
        // ========== GLOBAL VARIABLES ==========
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let isPaused = false;
        let startTime = 0;
        let timerInterval = null;
        let elapsedTime = 0;
        let currentRecording = null;
        let currentTranscript = '';
        
        // ========== DOM ELEMENTS ==========
        const recordBtn = document.getElementById('recordBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const stopBtn = document.getElementById('stopBtn');
        const transcribeBtn = document.getElementById('transcribeBtn');
        const status = document.getElementById('status');
        const timer = document.getElementById('timer');
        const audioContainer = document.getElementById('audioContainer');
        const audioPlayback = document.getElementById('audioPlayback');
        const transcriptContainer = document.getElementById('transcriptContainer');
        const transcriptBox = document.getElementById('transcriptBox');
        const uploadStatus = document.getElementById('uploadStatus');
        const uploadMessage = document.getElementById('uploadMessage');
        const saveTranscriptBtn = document.getElementById('saveTranscriptBtn');
        
        // ========== INITIALIZE ==========
        console.log('Talk Track initialized with API key:', API_KEY);
        
        // ========== EVENT LISTENERS ==========
        recordBtn.addEventListener('click', startRecording);
        pauseBtn.addEventListener('click', togglePause);
        stopBtn.addEventListener('click', stopRecording);
        transcribeBtn.addEventListener('click', transcribeAudio);
        saveTranscriptBtn.addEventListener('click', saveTranscript);
        
        // ========== RECORDING FUNCTIONS ==========
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    }
                });
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 128000
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    currentRecording = {
                        blob: audioBlob,
                        duration: elapsedTime,
                        timestamp: new Date().toISOString()
                    };
                    
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayback.src = audioUrl;
                    audioContainer.style.display = 'block';
                    
                    stream.getTracks().forEach(track => track.stop());
                    
                    status.textContent = 'Recording saved!';
                    showStatus('‚úÖ Recording saved! Ready for transcription.', 'success');
                };
                
                mediaRecorder.start(1000);
                isRecording = true;
                startTime = Date.now();
                
                timerInterval = setInterval(() => {
                    elapsedTime = Math.floor((Date.now() - startTime) / 1000);
                    const mins = Math.floor(elapsedTime / 60);
                    const secs = elapsedTime % 60;
                    timer.textContent = `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
                }, 1000);
                
                status.textContent = 'Recording...';
                recordBtn.disabled = true;
                pauseBtn.disabled = false;
                stopBtn.disabled = false;
                
            } catch (error) {
                console.error('Recording error:', error);
                status.textContent = 'Error: ' + error.message;
                alert('Please allow microphone access to use this app.');
            }
        }
        
        function togglePause() {
            if (!mediaRecorder) return;
            
            if (isPaused) {
                mediaRecorder.resume();
                status.textContent = 'Recording...';
                pauseBtn.textContent = '‚è∏Ô∏è Pause';
                startTime = Date.now() - (elapsedTime * 1000);
            } else {
                mediaRecorder.pause();
                status.textContent = 'Paused (Inspection)';
                pauseBtn.textContent = '‚ñ∂Ô∏è Resume';
                clearInterval(timerInterval);
            }
            
            isPaused = !isPaused;
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                isPaused = false;
                
                status.textContent = 'Processing...';
                recordBtn.disabled = false;
                pauseBtn.disabled = true;
                stopBtn.disabled = true;
                pauseBtn.textContent = '‚è∏Ô∏è Pause';
                clearInterval(timerInterval);
            }
        }
        
        // ========== TRANSCRIPTION FUNCTIONS ==========
        async function transcribeAudio() {
            if (!currentRecording || !currentRecording.blob) {
                alert('Please record audio first!');
                return;
            }
            
            showStatus('Starting transcription...', 'processing');
            
            try {
                // Step 1: Upload audio
                showStatus('Uploading audio to AssemblyAI...', 'processing');
                const uploadResult = await uploadAudio(currentRecording.blob);
                
                if (!uploadResult.upload_url) {
                    throw new Error('Failed to get upload URL');
                }
                
                // Step 2: Start transcription
                showStatus('Starting transcription job...', 'processing');
                const transcriptId = await startTranscription(uploadResult.upload_url);
                
                // Step 3: Poll for results
                showStatus('AI is transcribing your meeting...', 'processing');
                const transcript = await pollTranscription(transcriptId);
                
                // Step 4: Display transcript
                currentTranscript = transcript;
                displayTranscript(transcript);
                
                showStatus('‚úÖ Transcription complete!', 'success');
                
            } catch (error) {
                console.error('Transcription error:', error);
                showStatus(`‚ùå Error: ${error.message}`, 'error');
                
                // Fallback to mock transcription
                if (confirm('AI service issue. Use demo transcription?')) {
                    useMockTranscription();
                }
            }
        }
        
        async function uploadAudio(audioBlob) {
            console.log('Uploading audio blob:', audioBlob.size, 'bytes');
            
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.webm');
            
            const response = await fetch('https://api.assemblyai.com/v2/upload', {
                method: 'POST',
                headers: {
                    'Authorization': API_KEY
                },
                body: formData
            });
            
            if (!response.ok) {
                throw new Error(`Upload failed: ${response.status}`);
            }
            
            return await response.json();
        }
        
        async function startTranscription(audioUrl) {
            const response = await fetch('https://api.assemblyai.com/v2/transcript', {
                method: 'POST',
                headers: {
                    'Authorization': API_KEY,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    audio_url: audioUrl,
                    language_code: 'en',
                    punctuate: true,
                    format_text: true,
                    speaker_labels: true
                })
            });
            
            if (!response.ok) {
                throw new Error(`Transcription start failed: ${response.status}`);
            }
            
            const data = await response.json();
            return data.id;
        }
        
        async function pollTranscription(transcriptId) {
            let attempts = 0;
            const maxAttempts = 40; // 2 minutes max
            
            while (attempts < maxAttempts) {
                const response = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
                    headers: {
                        'Authorization': API_KEY
                    }
                });
                
                const data = await response.json();
                
                if (data.status === 'completed') {
                    return data.text;
                } else if (data.status === 'error') {
                    throw new Error(data.error);
                }
                
                // Update status every 5 attempts
                if (attempts % 5 === 0) {
                    showStatus(`Transcribing... (${data.status})`, 'processing');
                }
                
                // Wait 3 seconds before next poll
                await new Promise(resolve => setTimeout(resolve, 3000));
                attempts++;
            }
            
            throw new Error('Transcription timeout');
        }
        
        function useMockTranscription() {
            setTimeout(() => {
                const mockTranscript = `SALES REP: Good morning, I'm Alex from TalkTrack. Thanks for the meeting today.
                
CLIENT: No problem. I'm interested in what you have to offer.

SALES REP: Great. Our platform records sales meetings, transcribes them with AI, and analyzes against your sales framework. It identifies exactly where reps can improve.

CLIENT: How accurate is the transcription?

SALES REP: We use AssemblyAI which has 95%+ accuracy. It even identifies different speakers automatically.

CLIENT: What's the pricing?

SALES REP: We start at $997/month for up to 10 reps. Most clients see ROI within 30 days from increased close rates.

CLIENT: Let me discuss with my team and get back to you.`;

                currentTranscript = mockTranscript;
                displayTranscript(mockTranscript);
                
                showStatus('‚úÖ Demo transcription complete!', 'success');
            }, 1500);
        }
        
        function displayTranscript(text) {
            const paragraphs = text.split('\n\n').filter(p => p.trim());
            const formatted = paragraphs.map(p => `<p>${p.trim()}</p>`).join('');
            
            transcriptBox.innerHTML = formatted;
            transcriptContainer.style.display = 'block';
            transcriptContainer.scrollIntoView({ behavior: 'smooth' });
        }
        
        function saveTranscript() {
            if (!currentTranscript) {
                alert('No transcript to save!');
                return;
            }
            
            const blob = new Blob([currentTranscript], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            
            const date = new Date().toISOString().split('T')[0];
            a.href = url;
            a.download = `talk-track-transcript-${date}.txt`;
            
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            
            showStatus('‚úÖ Transcript saved!', 'success');
        }
        
        function showStatus(message, type) {
            uploadMessage.textContent = message;
            uploadStatus.className = 'upload-status';
            
            if (type === 'success') {
                uploadStatus.style.background = 'rgba(16, 185, 129, 0.2)';
                uploadStatus.style.border = '1px solid rgba(16, 185, 129, 0.5)';
            } else if (type === 'error') {
                uploadStatus.style.background = 'rgba(239, 68, 68, 0.2)';
                uploadStatus.style.border = '1px solid rgba(239, 68, 68, 0.5)';
            } else {
                uploadStatus.style.background = 'rgba(59, 130, 246, 0.2)';
                uploadStatus.style.border = '1px solid rgba(59, 130, 246, 0.5)';
            }
            
            uploadStatus.style.display = 'block';
            
            // Auto-hide success messages
            if (type === 'success') {
                setTimeout(() => {
                    uploadStatus.style.display = 'none';
                }, 3000);
            }
        }
        
        // Prevent accidental refresh during recording
        window.addEventListener('beforeunload', (e) => {
            if (isRecording) {
                e.preventDefault();
                e.returnValue = 'You are currently recording. Leave anyway?';
            }
        });
    </script>
</body>
</html>
