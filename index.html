<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Talk Track - Sales Meeting Recorder</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; color: white; }
        .container { max-width: 500px; margin: 0 auto; background: rgba(255,255,255,0.1); backdrop-filter: blur(10px); border-radius: 20px; padding: 25px; }
        h1 { text-align: center; margin-bottom: 20px; }
        .status-box { background: rgba(0,0,0,0.2); border-radius: 15px; padding: 20px; margin: 20px 0; text-align: center; }
        #status { font-size: 18px; font-weight: 500; }
        .timer { font-size: 48px; font-weight: 700; margin: 15px 0; }
        .controls { display: grid; grid-template-columns: repeat(3, 1fr); gap: 12px; margin: 25px 0; }
        .btn { padding: 16px; border: none; border-radius: 12px; font-size: 16px; font-weight: 600; cursor: pointer; color: white; display: flex; flex-direction: column; align-items: center; gap: 8px; }
        .btn:active { transform: scale(0.95); }
        .btn:disabled { opacity: 0.5; cursor: not-allowed; }
        .record-btn { background: linear-gradient(45deg, #ef4444, #dc2626); }
        .pause-btn { background: linear-gradient(45deg, #f59e0b, #d97706); }
        .stop-btn { background: linear-gradient(45deg, #10b981, #059669); }
        .transcribe-btn { background: linear-gradient(45deg, #3b82f6, #1d4ed8); }
        .audio-container { margin-top: 30px; display: none; }
        audio { width: 100%; border-radius: 10px; margin: 10px 0; }
        .upload-status { background: rgba(0,0,0,0.2); border-radius: 10px; padding: 15px; margin-top: 20px; text-align: center; display: none; }
        .transcript-container { margin-top: 20px; display: none; }
        .transcript-box { background: rgba(0,0,0,0.2); border-radius: 10px; padding: 15px; max-height: 300px; overflow-y: auto; text-align: left; line-height: 1.5; }
        .progress-bar { width: 100%; height: 6px; background: rgba(255,255,255,0.2); border-radius: 3px; margin-top: 10px; overflow: hidden; }
        .progress-fill { height: 100%; background: #3b82f6; width: 0%; transition: width 0.3s; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Talk Track</h1>
        
        <div class="status-box">
            <div id="status">Ready to record</div>
            <div class="timer" id="timer">00:00</div>
        </div>
        
        <div class="controls">
            <button class="btn record-btn" id="recordBtn">‚óè Record</button>
            <button class="btn pause-btn" id="pauseBtn" disabled>‚è∏Ô∏è Pause</button>
            <button class="btn stop-btn" id="stopBtn" disabled>‚èπÔ∏è Stop</button>
        </div>
        
        <div class="audio-container" id="audioContainer">
            <p>Your recording:</p>
            <audio id="audioPlayback" controls></audio>
            <button class="btn transcribe-btn" id="transcribeBtn" style="width:100%;margin-top:15px;">ü§ñ Transcribe with AI</button>
        </div>
        
        <div class="transcript-container" id="transcriptContainer">
            <h3>üìÑ Transcript</h3>
            <div class="transcript-box" id="transcriptBox"></div>
            <div class="progress-bar" id="progressBar" style="display:none;">
                <div class="progress-fill" id="progressFill"></div>
            </div>
            <div id="progressText" style="font-size:12px;text-align:center;margin-top:5px;"></div>
            <button class="btn" id="saveTranscriptBtn" style="background:linear-gradient(45deg,#10b981,#059669);width:100%;margin-top:15px;">
                üíæ Save Transcript
            </button>
        </div>
        
        <div class="upload-status" id="uploadStatus">
            <div id="uploadMessage">Processing...</div>
        </div>
    </div>

    <script>
        // ========== CONFIGURATION ==========
        const API_KEY = '6fc9030ecb074dc88055f8a257aff0f7';
        
        // CORS Proxy - FIXES THE BLOCKING ISSUE
        const CORS_PROXY = 'https://cors-anywhere.herokuapp.com/';
        // Alternative proxies if one fails:
        // const CORS_PROXY = 'https://api.allorigins.win/raw?url=';
        // const CORS_PROXY = 'https://thingproxy.freeboard.io/fetch/';
        
        // ========== GLOBAL VARIABLES ==========
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let isPaused = false;
        let startTime = 0;
        let timerInterval = null;
        let elapsedTime = 0;
        let currentRecording = null;
        let currentTranscript = '';
        
        // ========== DOM ELEMENTS ==========
        const recordBtn = document.getElementById('recordBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const stopBtn = document.getElementById('stopBtn');
        const transcribeBtn = document.getElementById('transcribeBtn');
        const status = document.getElementById('status');
        const timer = document.getElementById('timer');
        const audioContainer = document.getElementById('audioContainer');
        const audioPlayback = document.getElementById('audioPlayback');
        const transcriptContainer = document.getElementById('transcriptContainer');
        const transcriptBox = document.getElementById('transcriptBox');
        const uploadStatus = document.getElementById('uploadStatus');
        const uploadMessage = document.getElementById('uploadMessage');
        const saveTranscriptBtn = document.getElementById('saveTranscriptBtn');
        const progressBar = document.getElementById('progressBar');
        const progressFill = document.getElementById('progressFill');
        const progressText = document.getElementById('progressText');
        
        // ========== EVENT LISTENERS ==========
        recordBtn.addEventListener('click', startRecording);
        pauseBtn.addEventListener('click', togglePause);
        stopBtn.addEventListener('click', stopRecording);
        transcribeBtn.addEventListener('click', transcribeAudio);
        saveTranscriptBtn.addEventListener('click', saveTranscript);
        
        // ========== RECORDING FUNCTIONS ==========
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000, // Better for speech recognition
                        channelCount: 1    // Mono is better for transcription
                    }
                });
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 64000 // Lower bitrate for speech
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    currentRecording = {
                        blob: audioBlob,
                        duration: elapsedTime,
                        timestamp: new Date().toISOString(),
                        name: `Sales Meeting ${new Date().toLocaleDateString()}`
                    };
                    
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayback.src = audioUrl;
                    audioContainer.style.display = 'block';
                    
                    stream.getTracks().forEach(track => track.stop());
                    
                    status.textContent = 'Recording saved!';
                    showStatus('‚úÖ Recording saved! Ready for transcription.', 'success');
                };
                
                mediaRecorder.start(1000);
                isRecording = true;
                startTime = Date.now();
                
                timerInterval = setInterval(() => {
                    elapsedTime = Math.floor((Date.now() - startTime) / 1000);
                    const mins = Math.floor(elapsedTime / 60);
                    const secs = elapsedTime % 60;
                    timer.textContent = `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
                }, 1000);
                
                status.textContent = 'Recording...';
                recordBtn.disabled = true;
                pauseBtn.disabled = false;
                stopBtn.disabled = false;
                
            } catch (error) {
                console.error('Recording error:', error);
                status.textContent = 'Error: ' + error.message;
                alert('Please allow microphone access to use this app.');
            }
        }
        
        function togglePause() {
            if (!mediaRecorder) return;
            
            if (isPaused) {
                mediaRecorder.resume();
                status.textContent = 'Recording...';
                pauseBtn.textContent = '‚è∏Ô∏è Pause';
                startTime = Date.now() - (elapsedTime * 1000);
            } else {
                mediaRecorder.pause();
                status.textContent = 'Paused (Inspection)';
                pauseBtn.textContent = '‚ñ∂Ô∏è Resume';
                clearInterval(timerInterval);
            }
            
            isPaused = !isPaused;
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                isPaused = false;
                
                status.textContent = 'Processing...';
                recordBtn.disabled = false;
                pauseBtn.disabled = true;
                stopBtn.disabled = true;
                pauseBtn.textContent = '‚è∏Ô∏è Pause';
                clearInterval(timerInterval);
            }
        }
        
        // ========== TRANSCRIPTION FUNCTIONS (WITH CORS FIX) ==========
        async function transcribeAudio() {
            if (!currentRecording || !currentRecording.blob) {
                alert('Please record audio first!');
                return;
            }
            
            // Reset UI
            transcriptContainer.style.display = 'block';
            transcriptBox.innerHTML = 'Starting transcription...';
            progressBar.style.display = 'block';
            updateProgress(0, 'Starting...');
            
            try {
                // Step 1: Upload audio through CORS proxy
                updateProgress(10, 'Uploading audio...');
                const uploadUrl = await uploadAudioWithProxy(currentRecording.blob);
                
                // Step 2: Start transcription through CORS proxy
                updateProgress(30, 'Starting transcription job...');
                const transcriptId = await startTranscriptionWithProxy(uploadUrl);
                
                // Step 3: Poll for results through CORS proxy
                updateProgress(50, 'AI is transcribing...');
                const transcript = await pollTranscriptionWithProxy(transcriptId);
                
                // Step 4: Display results
                updateProgress(100, 'Complete!');
                currentTranscript = transcript;
                displayTranscript(transcript);
                
                showStatus('‚úÖ Transcription complete!', 'success');
                
                // Hide progress bar after success
                setTimeout(() => {
                    progressBar.style.display = 'none';
                }, 2000);
                
            } catch (error) {
                console.error('Transcription error:', error);
                transcriptBox.innerHTML = `<p style="color:#f87171">‚ùå Error: ${error.message}</p>`;
                progressBar.style.display = 'none';
                
                // Fallback to mock transcription
                if (confirm('AI transcription failed. Use demo transcription?')) {
                    useMockTranscription();
                }
            }
        }
        
        // UPLOAD WITH CORS PROXY
        async function uploadAudioWithProxy(audioBlob) {
            console.log('Uploading audio via CORS proxy...');
            
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.webm');
            
            // Use CORS proxy for the upload
            const proxyUploadUrl = CORS_PROXY + 'https://api.assemblyai.com/v2/upload';
            
            const response = await fetch(proxyUploadUrl, {
                method: 'POST',
                headers: {
                    'Authorization': API_KEY,
                    'X-Requested-With': 'XMLHttpRequest'
                },
                body: formData
            });
            
            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`Upload failed: ${response.status} - ${errorText}`);
            }
            
            const data = await response.json();
            console.log('Upload successful:', data);
            return data.upload_url;
        }
        
        // START TRANSCRIPTION WITH CORS PROXY
        async function startTranscriptionWithProxy(audioUrl) {
            console.log('Starting transcription via CORS proxy...');
            
            const proxyTranscribeUrl = CORS_PROXY + 'https://api.assemblyai.com/v2/transcript';
            
            const response = await fetch(proxyTranscribeUrl, {
                method: 'POST',
                headers: {
                    'Authorization': API_KEY,
                    'Content-Type': 'application/json',
                    'X-Requested-With': 'XMLHttpRequest'
                },
                body: JSON.stringify({
                    audio_url: audioUrl,
                    language_code: 'en',
                    punctuate: true,
                    format_text: true,
                    speaker_labels: true
                })
            });
            
            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`Transcription start failed: ${response.status} - ${errorText}`);
            }
            
            const data = await response.json();
            console.log('Transcription job created:', data);
            return data.id;
        }
        
        // POLL TRANSCRIPTION WITH CORS PROXY
        async function pollTranscriptionWithProxy(transcriptId, timeoutMs = 180000) {
            console.log('Polling transcription via CORS proxy...');
            
            const startTime = Date.now();
            let attempts = 0;
            
            while (Date.now() - startTime < timeoutMs) {
                attempts++;
                
                const proxyPollUrl = CORS_PROXY + `https://api.assemblyai.com/v2/transcript/${transcriptId}`;
                
                const response = await fetch(proxyPollUrl, {
                    headers: {
                        'Authorization': API_KEY,
                        'X-Requested-With': 'XMLHttpRequest'
                    }
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Poll failed: ${response.status} - ${errorText}`);
                }
                
                const data = await response.json();
                
                if (data.status === 'completed') {
                    console.log('Transcription completed!');
                    return data.text;
                }
                
                if (data.status === 'error') {
                    throw new Error(`Transcription error: ${data.error}`);
                }
                
                // Update progress
                const progress = 50 + Math.min(45, (attempts * 5));
                const statusText = data.status.charAt(0).toUpperCase() + data.status.slice(1);
                updateProgress(progress, `${statusText}... (Attempt ${attempts})`);
                
                // Wait before next poll
                await new Promise(resolve => setTimeout(resolve, 3000));
            }
            
            throw new Error('Transcription timeout after 3 minutes');
        }
        
        // MOCK TRANSCRIPTION FALLBACK
        function useMockTranscription() {
            transcriptBox.innerHTML = 'Generating demo transcript...';
            
            setTimeout(() => {
                const mockTranscript = `SALES REP: Good morning, I'm Alex from TalkTrack. Thanks for taking the meeting today.
                
CLIENT: No problem. I'm interested in what you have to offer.

SALES REP: Great. I understand you're looking to improve your sales team's performance. Is that correct?

CLIENT: Yes, we're struggling with consistency in our sales conversations.

SALES REP: Perfect. Our platform records sales meetings, transcribes them with AI, and analyzes against your sales framework. It identifies exactly where reps can improve.

CLIENT: How accurate is the transcription?

SALES REP: We use AssemblyAI which has 95%+ accuracy. It even identifies different speakers automatically.

CLIENT: What about pricing?

SALES REP: We have three tiers starting at $997/month for up to 10 reps. Most clients see ROI within 30 days from increased close rates.

CLIENT: Can we try it first?

SALES REP: Absolutely. I'll set up a 14-day trial for your team. When would you like to start?`;

                currentTranscript = mockTranscript;
                displayTranscript(mockTranscript);
                progressBar.style.display = 'none';
                showStatus('‚úÖ Demo transcription complete!', 'success');
            }, 1500);
        }
        
        // ========== HELPER FUNCTIONS ==========
        function displayTranscript(text) {
            const paragraphs = text.split('\n\n').filter(p => p.trim());
            const formatted = paragraphs.map(p => `<p>${p.trim()}</p>`).join('');
            transcriptBox.innerHTML = formatted;
        }
        
        function updateProgress(percent, text) {
            progressFill.style.width = percent + '%';
            progressText.textContent = text;
        }
        
        function saveTranscript() {
            if (!currentTranscript) {
                alert('No transcript to save!');
                return;
            }
            
            const blob = new Blob([currentTranscript], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            
            const date = new Date().toISOString().split('T')[0];
            a.href = url;
            a.download = `talk-track-transcript-${date}.txt`;
            
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            
            showStatus('‚úÖ Transcript saved!', 'success');
        }
        
        function showStatus(message, type) {
            uploadMessage.textContent = message;
            uploadStatus.className = 'upload-status';
            
            if (type === 'success') {
                uploadStatus.style.background = 'rgba(16, 185, 129, 0.2)';
                uploadStatus.style.border = '1px solid rgba(16, 185, 129, 0.5)';
            } else if (type === 'error') {
                uploadStatus.style.background = 'rgba(239, 68, 68, 0.2)';
                uploadStatus.style.border = '1px solid rgba(239, 68, 68, 0.5)';
            } else {
                uploadStatus.style.background = 'rgba(59, 130, 246, 0.2)';
                uploadStatus.style.border = '1px solid rgba(59, 130, 246, 0.5)';
            }
            
            uploadStatus.style.display = 'block';
            
            if (type === 'success') {
                setTimeout(() => {
                    uploadStatus.style.display = 'none';
                }, 3000);
            }
        }
        
        // Test CORS proxy on load
        window.addEventListener('load', async () => {
            console.log('Testing CORS proxy...');
            try {
                // Test if CORS proxy is working
                const testResponse = await fetch(CORS_PROXY + 'https://api.assemblyai.com/v2/', {
                    headers: { 'Authorization': API_KEY }
                });
                
                if (testResponse.ok) {
                    console.log('‚úÖ CORS proxy is working!');
                } else {
                    console.warn('‚ö†Ô∏è CORS proxy might have issues');
                }
            } catch (error) {
                console.warn('‚ö†Ô∏è CORS proxy test failed:', error.message);
            }
        });
        
        // Prevent accidental refresh during recording
        window.addEventListener('beforeunload', (e) => {
            if (isRecording) {
                e.preventDefault();
                e.returnValue = 'You are currently recording. Leave anyway?';
            }
        });
    </script>
</body>
</html>
